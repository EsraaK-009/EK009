{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arabic Topic Modeling with Textacy And Spacy-udpipe\n",
        "> Textacy for sure is a powerful Library to use with NLP, but if you open the docs you'll find it doesn't support any lanuage that spacy doesn't support, this notebook is a simple introduction to use textacy for Arabic language or any other language that spacy doesn't have a model for it til now.\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Esraa Khaled\n",
        "- categories: [fastpages, jupyter]"
      ],
      "metadata": {
        "id": "F5opRX4dNyY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7ttOXj04b1gO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install spacy-udpipe\n",
        "!pip install textacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading udpipe model\n",
        "\n",
        "> First, we have to install the Arabic model from this link: [Models](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-3131) And upload it to our colab notebook."
      ],
      "metadata": {
        "id": "bl5oWvo9QEPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy_udpipe\n",
        "import textacy\n",
        "import textacy.tm\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBi_aLF6dAKT",
        "outputId": "422b5150-94fc-4528-dc15-8b2ee756d7f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spacy_udpipe.download(\"ar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "learf39nCsgf",
        "outputId": "f994c371-51f5-4407-ea29-8e9b36e3278d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already downloaded a model for the 'ar' language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy_udpipe.load_from_path(lang=\"ar\",\n",
        "                                  path=\"./arabic-padt-ud-2.5-191206.udpipe\",\n",
        "                                  meta={\"description\": \"Custom 'ar' model\"})\n",
        "text = \"القاهرة هي المكان المفضل لدي\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_)"
      ],
      "metadata": {
        "id": "kTc3WdGDcCkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75aaa139-c99c-44af-9e38-d4c16d1e3598"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "القاهرة قَاهِرَة NOUN nsubj\n",
            "هي هُوَ PRON nmod\n",
            "المكان مَكَان NOUN ROOT\n",
            "المفضل المفضل ADJ amod\n",
            "لدي لَدَى ADP case\n",
            "ي هُوَ PRON nmod\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now we have our model as \"nlp\" and we can use it with many other libraries. "
      ],
      "metadata": {
        "id": "PkQ3q6i_RK01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Without_namesAndSW.csv\")\n",
        "#df.info()"
      ],
      "metadata": {
        "id": "jc3eDVXKSysO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topic Modeling\n",
        "\n",
        "To get the topics we need to go through these steps:\n",
        "\n",
        "- To make it easy and use the options we have in textacy we'll convert our data to textacy's corpus. \n",
        "- Get tokens of every document.\n",
        "- Specify the vectorizer we want.\n",
        "- Make the doc-term-matrix. **Note: This matrix can be used with gensim models if you Transpose it.**"
      ],
      "metadata": {
        "id": "DRHQjpzBR3QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = textacy.Corpus(nlp, data=df['No_stopWords'])"
      ],
      "metadata": {
        "id": "fRklLirvy7h-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40m3N_UhEcbc",
        "outputId": "982295b2-fde1-4f39-8f09-37212b322d6c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus(29 docs, 44526 tokens)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_docs = (\n",
        "   (term.lemma_ for term in textacy.extract.terms(doc, ngs=1, ents=True))\n",
        "    for doc in corpus)"
      ],
      "metadata": {
        "id": "951pBfzxy0Ts"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = textacy.representations.vectorizers.Vectorizer(\n",
        "   tf_type=\"linear\", idf_type=\"smooth\", norm=\"l2\",\n",
        "    min_df=3, max_df=0.95)"
      ],
      "metadata": {
        "id": "1nywJiCk1hsB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another Note: You can get the id2word dictionary also from the vectorizer here and use it with your code.**"
      ],
      "metadata": {
        "id": "pu-Ltkm_TEMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse-hide\n",
        "\n",
        "id2word = vectorizer.id_to_term"
      ],
      "metadata": {
        "id": "H3Sz7i-9TGJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix = vectorizer.fit_transform(tokenized_docs)"
      ],
      "metadata": {
        "id": "LxpnLmIP1pef"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-wob6zP1uHX",
        "outputId": "71429f91-8b6b-4e6d-eb96-0583ebf391a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<29x1185 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 9628 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = textacy.tm.topic_model.TopicModel(\"nmf\", n_topics=4)\n",
        "model.fit(doc_term_matrix)"
      ],
      "metadata": {
        "id": "Ry8oGkBc1y1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbccb7be-73af-4e62-a9fa-608d7133fd71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2fupPfn2cGZ",
        "outputId": "e9a8769d-7449-4a93-bf0e-5ec3b0dbbac7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TopicModel(n_topics=4, model=NMF)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inspection:"
      ],
      "metadata": {
        "id": "u8i4vWPcTvOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top Topic Terms:**"
      ],
      "metadata": {
        "id": "AMeHA_xdT97M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_topic_matrix = model.transform(doc_term_matrix)\n",
        "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, topics=[0,1,2,3]):\n",
        "     print(\"topic\", topic_idx, \":\", \"   \".join(top_terms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6Q4tI9q2fgi",
        "outputId": "4dd927bd-d000-407d-c078-054f1fd5e885"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0 : بَنك   حِسَاب   المدعى   اِعتِمَاد   مَبلَغ   فَائِدَة   شَرِكَة   تَارِيخ   خَبِير   مَديُونِيَّة\n",
            "topic 1 : أُجرَة   ـ   وَفَاء   مَستاجَر   بالاجرة   تَكلِيف   تَكرَار   إِعلَان   اِستِئنَاف   إِخلَاء\n",
            "topic 2 : شَرِكَة   أَوَّل   قَرَار   جَمعِيَّة   شَرِيك   تَصفِيَة   عَمَل   إِدَارَة   ثَانِي   87\n",
            "topic 3 : اَلَّذِي   2002   تَابَع   يكفى   دَفع   قَول   تَحقِيق   قِسم   اِثنَان   وكفايت\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Weights:**"
      ],
      "metadata": {
        "id": "BSH5UhduUHR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, val in enumerate(model.topic_weights(doc_topic_matrix)):\n",
        "     print(i, val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEwarw0GISUR",
        "outputId": "01972501-1be5-412b-d184-fcf3bf3c6eff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.33786064340985056\n",
            "1 0.4085472464974949\n",
            "2 0.13763662553716402\n",
            "3 0.11595548455549054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documents Topics:**"
      ],
      "metadata": {
        "id": "7V2Sry9LUMP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for doc_idx, topics in model.top_doc_topics(doc_topic_matrix):\n",
        "     print(\"Doc ID: \", doc_idx,\":\", topics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYVSKFr8J6xN",
        "outputId": "a0daf74c-4b93-4526-8789-87fe3294248e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID:  0 : (0, 3, 2)\n",
            "ID:  1 : (0, 2, 3)\n",
            "ID:  2 : (0, 2, 3)\n",
            "ID:  3 : (0, 3, 2)\n",
            "ID:  4 : (0, 3, 2)\n",
            "ID:  5 : (0, 3, 2)\n",
            "ID:  6 : (0, 3, 2)\n",
            "ID:  7 : (0, 3, 2)\n",
            "ID:  8 : (0, 3, 2)\n",
            "ID:  9 : (0, 2, 3)\n",
            "ID:  10 : (3, 2, 0)\n",
            "ID:  11 : (0, 2, 3)\n",
            "ID:  12 : (0, 2, 3)\n",
            "ID:  13 : (3, 2, 0)\n",
            "ID:  14 : (0, 3, 2)\n",
            "ID:  15 : (0, 1, 3)\n",
            "ID:  16 : (0, 1, 3)\n",
            "ID:  17 : (0, 1, 3)\n",
            "ID:  18 : (0, 1, 3)\n",
            "ID:  19 : (0, 1, 2)\n",
            "ID:  20 : (0, 1, 3)\n",
            "ID:  21 : (0, 2, 1)\n",
            "ID:  22 : (0, 1, 3)\n",
            "ID:  23 : (0, 1, 3)\n",
            "ID:  24 : (0, 1, 3)\n",
            "ID:  25 : (0, 1, 3)\n",
            "ID:  26 : (0, 1, 2)\n",
            "ID:  27 : (0, 2, 1)\n",
            "ID:  28 : (0, 2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.termite_plot(doc_term_matrix, vectorizer.id_to_term,\n",
        "#                    topics=-1,  n_terms=25, sort_terms_by=\"seriation\")"
      ],
      "metadata": {
        "id": "-uSP5ijtMElR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"nmf-4topics.pkl\")"
      ],
      "metadata": {
        "id": "osIFr_6eNGw2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}